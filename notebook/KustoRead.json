{
	"name": "KustoRead",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "spark34a2",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "12708e65-e2f4-4804-9721-374e6a21ab62"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/216ca57c-8613-4c54-8960-1e5821b6dc8d/resourceGroups/SDK_E2E_TEST/providers/Microsoft.Synapse/workspaces/synapsekustosparkppe/bigDataPools/spark34a2",
				"name": "spark34a2",
				"type": "Spark",
				"endpoint": "https://synapsekustosparkppe.dev.azuresynapse-test.azure.net/livyApi/versions/2019-11-01-preview/sparkPools/spark34a2",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.4",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "scala"
					}
				},
				"source": [
					"%%spark\n",
					"println(spark.conf.get(\"spark.synapse.vhd.id\"))"
				],
				"execution_count": 1
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**Run in single mode**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "python"
					},
					"collapsed": false
				},
				"source": [
					"%%pyspark\n",
					"kustoDf  = spark.read \\\n",
					"    .format(\"com.microsoft.kusto.spark.synapse.datasource\") \\\n",
					"    .option(\"spark.synapse.linkedService\", \"sdktestcluster\") \\\n",
					"    .option(\"kustoDatabase\", \"e2e\") \\\n",
					"    .option(\"kustoQuery\", \"SparkSpecialChars | extend UserPrincipalName = base64_encode_tostring(UserPrincipalName)\") \\\n",
					"    .load()\n",
					"\n",
					"from pyspark.sql.functions import unbase64\n",
					"\n",
					"display(kustoDf.withColumn('UserPrincipalName2', unbase64(kustoDf.UserPrincipalName).cast(\"string\")))\n",
					""
				],
				"execution_count": 4
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**Run in distributed mode**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "python"
					},
					"collapsed": false
				},
				"source": [
					"%%pyspark\n",
					"kustoDfAad  = spark.read \\\n",
					"    .format(\"com.microsoft.kusto.spark.synapse.datasource\") \\\n",
					"    .option(\"kustoDatabase\", \"spark\") \\\n",
					"    .option(\"kustoCluster\", \"https://sdktestcluster.southeastasia.dev.kusto.windows.net\") \\\n",
					"    .option(\"kustoQuery\", \"KustoAirlineDataParquetTransactional2\t | take 2\") \\\n",
					"    .load()\n",
					"\n",
					"display(kustoDfAad)\n",
					"\n",
					""
				],
				"execution_count": 3
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "python"
					},
					"collapsed": false
				},
				"source": [
					"%%pyspark\r\n",
					"\r\n",
					"# Read data from Azure Data Explorer table(s)\r\n",
					"# Full Sample Code available at: https://github.com/Azure/azure-kusto-spark/blob/master/samples/src/main/python/SynapseSample.py\r\n",
					"\r\n",
					"kustoDfDistributed  = spark.read \\\r\n",
					"    .format(\"com.microsoft.kusto.spark.synapse.datasource\") \\\r\n",
					"    .option(\"spark.synapse.linkedService\", \"sdktestcluster\") \\\r\n",
					"    .option(\"kustoDatabase\", \"spark\") \\\r\n",
					"    .option(\"kustoQuery\", \"KustoAirlineDataParquetTransactional2 | where Year >= 1987\t| take 10000\") \\\r\n",
					"    .option(\"readMode\", \"ForceDistributedMode\") \\\r\n",
					"    .load()\r\n",
					"\r\n",
					"display(kustoDfDistributed)\r\n",
					""
				],
				"execution_count": 4
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**Create a set of random data with all the datatpes**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "scala"
					}
				},
				"source": [
					"%%spark\r\n",
					"\r\n",
					"import scala.util.Random\r\n",
					"import java.time.Instant\r\n",
					"import java.util.UUID\r\n",
					"\r\n",
					"val aDynamic = s\"\"\"{\"itemid\":\"X-Wing-${Random.nextInt()}\" , \"price\": ${Random.nextInt()},\"quantity\": ${Random.nextInt()}\"\"\" //s\"\"\"{\"itemid\":  , \"in_stock\": true,\"price\": ${Random.nextInt()},\"quantity\": 23 }\"\"\"\r\n",
					"\r\n",
					"val data = 1 to 100000 map(x =>  (Random.nextBoolean(), Instant.now().toString() , aDynamic ,UUID.randomUUID().toString() ,Random.nextInt(),Random.nextLong(),Random.nextDouble(),Random.nextString(5),123456789.12345678910d))\r\n",
					"\r\n",
					"val allTypesDf = spark.sqlContext.createDataFrame(data).toDF(\"BoolType\", \"DateTimeType\", \"DynamicType\",\"GuidType\", \"IntType\", \"LongType\",\"RealType\",\"StringType\",\"DecimalType\")\r\n",
					"//(BoolType:bool,DateTimeType:datetime,DynamicType:dynamic,GuidType:guid,IntType:int,LongType:long,RealType:real,StringType:string,DecimalType:decimal)\r\n",
					"\r\n",
					"allTypesDf.write.format(\"com.microsoft.kusto.spark.synapse.datasource\").option(\"spark.synapse.linkedService\", \"sdktestcluster\").option(\"kustoDatabase\", \"spark\").option(\"kustoTable\", \"AllDataTypesTransactionalSpark33\").option(\"tableCreateOptions\",\"CreateIfNotExist\").mode(\"Append\").save()\r\n",
					"//allTypesDf.write.format(\"com.microsoft.kusto.spark.synapse.datasource\").option(\"spark.synapse.linkedService\", \"sdktestcluster\").option(\"kustoDatabase\", \"spark\").option(\"kustoTable\", \"AllDataTypesQueuedSpark33\").option(\"tableCreateOptions\",\"CreateIfNotExist\").option(\"writeMode\",\"Queued\").mode(\"Append\").save()"
				],
				"execution_count": 10
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**This will not load immediately, but is a good test for the _queued_ mode**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "scala"
					}
				},
				"source": [
					"%%spark\r\n",
					"allTypesDf.write.format(\"com.microsoft.kusto.spark.synapse.datasource\").option(\"spark.synapse.linkedService\", \"sdktestcluster\").option(\"kustoDatabase\", \"spark\").option(\"kustoTable\", \"[All-DataTypes-QueuedSpark33]\").option(\"tableCreateOptions\",\"CreateIfNotExist\").option(\"writeMode\",\"Queued\").mode(\"Append\").save()"
				],
				"execution_count": 6
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "python"
					},
					"collapsed": false
				},
				"source": [
					"%%pyspark\r\n",
					"\r\n",
					"# Read data from Azure Data Explorer table(s)\r\n",
					"# Full Sample Code available at: https://github.com/Azure/azure-kusto-spark/blob/master/samples/src/main/python/SynapseSample.py\r\n",
					"kustoDfAllTypes  = spark.read \\\r\n",
					"    .format(\"com.microsoft.kusto.spark.synapse.datasource\") \\\r\n",
					"    .option(\"spark.synapse.linkedService\", \"sdktestcluster\") \\\r\n",
					"    .option(\"kustoDatabase\", \"spark\") \\\r\n",
					"    .option(\"kustoQuery\", \"KustoAirlineDataParquetTransactional2 | where Year >= 1987\t | take 100\") \\\r\n",
					"    .option(\"readMode\", \"ForceDistributedMode\") \\\r\n",
					"    .load()\r\n",
					"\r\n",
					"display(kustoDfAllTypes)"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "python"
					},
					"collapsed": false
				},
				"source": [
					"%%pyspark\r\n",
					"\r\n",
					"# Read data from Azure Data Explorer table(s)\r\n",
					"# Full Sample Code available at: https://github.com/Azure/azure-kusto-spark/blob/master/samples/src/main/python/SynapseSample.py\r\n",
					"transactionalModeCount  = spark.read \\\r\n",
					"    .format(\"com.microsoft.kusto.spark.synapse.datasource\") \\\r\n",
					"    .option(\"spark.synapse.linkedService\", \"sdktestcluster\") \\\r\n",
					"    .option(\"kustoDatabase\", \"spark\") \\\r\n",
					"    .option(\"kustoQuery\", \"AllDataTypesTransactionalSpark33 | project DiffSecs = datetime_diff('second',ingestion_time(),todatetime(DateTimeType)) | summarize  count(),min(DiffSecs),max(DiffSecs),avg(DiffSecs)\") \\\r\n",
					"    .load()\r\n",
					"\r\n",
					"display(transactionalModeCount)"
				],
				"execution_count": 11
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "python"
					},
					"collapsed": false
				},
				"source": [
					"%%pyspark\r\n",
					"# Read data from Azure Data Explorer table(s)\r\n",
					"# Full Sample Code available at: https://github.com/Azure/azure-kusto-spark/blob/master/samples/src/main/python/SynapseSample.py\r\n",
					"queuedModeCount  = spark.read \\\r\n",
					"    .format(\"com.microsoft.kusto.spark.synapse.datasource\") \\\r\n",
					"    .option(\"spark.synapse.linkedService\", \"sdktestcluster\") \\\r\n",
					"    .option(\"kustoDatabase\", \"spark\") \\\r\n",
					"    .option(\"kustoQuery\", \"['All-DataTypes-QueuedSpark33'] | project DiffSecs = datetime_diff('second',ingestion_time(),todatetime(DateTimeType)) | summarize  count(),min(DiffSecs),max(DiffSecs),avg(DiffSecs)\") \\\r\n",
					"    .load()\r\n",
					"\r\n",
					"display(queuedModeCount)"
				],
				"execution_count": 13
			}
		]
	}
}